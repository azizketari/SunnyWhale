{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warnings:\n",
    "> Make sure that your VM has full permissions right (need rw GCS, and automl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud\n",
    "# !pip install google-cloud-storage\n",
    "# !pip install google-cloud-automl\n",
    "# !pip install opencv-python\n",
    "# !pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from google.cloud import automl_v1beta1 as automl\n",
    "# from google.cloud import storage\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "import fitz # pip install PyMuPDF\n",
    "import cv2 # pip install opencv-python\n",
    "from PIL import Image\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.misc\n",
    "from math import ceil\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Preprocessing pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_png(pdf_filename) :\n",
    "\n",
    "    pdf_dirname = os.path.dirname(pdf_filename)\n",
    "    \n",
    "    pdf_basename = os.path.basename(pdf_filename)\n",
    "    pdf_root, pdf_ext = os.path.splitext(pdf_basename)\n",
    "    img_filename = './data/{}.png'.format(pdf_root)\n",
    "    \n",
    "    if pdf_ext == '.pdf':\n",
    "    \n",
    "        pdf_document = fitz.open(pdf_filename)\n",
    "\n",
    "        page_pixmap = pdf_document.getPagePixmap(0,alpha=False)\n",
    "        page_pixmap.writePNG(img_filename)\n",
    "        return pdf_document.close()\n",
    "    \n",
    "\n",
    "def crop_img(img_filename):\n",
    "    \"\"\"\n",
    "    the first two numbers define the top-left coordinates of the outtake (x,y), \n",
    "    while the last two define the right-bottom coordinates of the outtake.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_filename)\n",
    "    img_basename = os.path.basename(img_filename)\n",
    "    img_root, img_ext = os.path.splitext(img_basename)\n",
    "    img2 = img.crop((23, 65, 780, 430))\n",
    "    return img2.save(\"./data/{}_cropped{}\".format(img_root,img_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_image(img_path, overlap=0.5, filter_size=(100,100,3)):\n",
    "    \"\"\"\n",
    "    Overlap is defined as the coverage between one patch to the next.\n",
    "    Regardless of the axis of the next image (horizontal or vertical)\n",
    "    Input:\n",
    "    ------\n",
    "    image: np.array\n",
    "    overlap: percentage\n",
    "    slices: tuple with patch shape used for model\n",
    "    Output:\n",
    "    ------\n",
    "    \"\"\"\n",
    "    #assumption: the height and width of input image is same\n",
    "    image = np.array(Image.open(img_path).convert('RGB'))\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    img_basename = os.path.basename(img_path)\n",
    "    img_root, img_ext = os.path.splitext(img_basename)\n",
    "    \n",
    "    m, n, depth = image.shape\n",
    "    m_patch, n_patch , depth= filter_size\n",
    "    stride = int(round(m_patch*(1-overlap)))\n",
    "    # p: number of smaller images\n",
    "    num_m, num_n = int(-(-m//stride)), int(-(-n//stride))\n",
    "    p = num_m * num_n\n",
    "\n",
    "    # pad: extra pixels needed to be added\n",
    "    pad_x = stride * num_m + (m_patch - stride) - m\n",
    "    pad_y = stride * num_n + (n_patch - stride) - n\n",
    "    # padd: pixels to be added in each side of the image\n",
    "    padd_x = int(pad_x / 2)\n",
    "    padd_y = int(pad_y / 2)\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    new_image = np.zeros((num_m*stride+(m_patch-stride), num_n*stride+(n_patch-stride), depth))\n",
    "    \n",
    "    new_image[padd_x:m+padd_x, padd_y:n+padd_y, :] = image\n",
    "\n",
    "    sliced_bytes = []\n",
    "    sliced_images = []\n",
    "    for i in range(num_m):\n",
    "        for j in range(num_n):\n",
    "            #sliced_bytes.append(new_image[i*stride:i*stride+m_patch, j*stride:j*stride+n_patch].tobytes())\n",
    "            sliced_images.append(new_image[i*stride:i*stride+m_patch, j*stride:j*stride+n_patch, :])    \n",
    "    \n",
    "    if os.path.isdir('./data/{}'.format(img_root)) == True:\n",
    "        for counter, img in enumerate(sliced_images):\n",
    "            scipy.misc.imsave(\"./data/{}/{}_slice{}{}\".format(img_root,img_root,\n",
    "                                                              counter,img_ext), img)\n",
    "    else:\n",
    "        os.mkdir('./data/{}'.format(img_root))\n",
    "        for counter, img in enumerate(sliced_images):\n",
    "            scipy.misc.imsave(\"./data/{}/{}_slice{}{}\".format(img_root,img_root,\n",
    "                                                              counter,img_ext), img)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Execute preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Earth images\n",
    "# for i in range(1,11):\n",
    "#     pdf_to_png('./data/image{}.pdf'.format(i))\n",
    "#     crop_img('./data/image{}.png'.format(i))\n",
    "#     slice_image('./data/image{}_cropped.png'.format(i),\n",
    "#                 filter_size=(200,200,3),overlap=0)\n",
    "    \n",
    "# # Mars images\n",
    "# for i in range(1,7):\n",
    "#     #pdf_to_png('./data/mars_image{}.pdf'.format(i))\n",
    "#     try:\n",
    "#         crop_img('./data/mars_image{}.png'.format(i))\n",
    "#         slice_image('./data/mars_image{}_cropped.png'.format(i),filter_size=(200,200,3),overlap=0)\n",
    "#     except:\n",
    "#         crop_img('./data/mars_image{}.jpg'.format(i))\n",
    "#         slice_image('./data/mars_image{}_cropped.jpg'.format(i),filter_size=(200,200,3),overlap=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "project_id = 'aketari-sandbox-vision'\n",
    "compute_region = 'us-central1'\n",
    "dataset_name = 'WhaleTail'\n",
    "dataset_gcs_path = 'gs://'\n",
    "bucket_name = 'aketari-sandbox-vision-vcm'\n",
    "csv_VM_path = './whale_data/{}.csv'.format(dataset_name)\n",
    "model_name_prefix = 'WhaleTail_'\n",
    "\n",
    "# automl_client = automl.AutoMlClient()\n",
    "# storage_client = storage.Client()\n",
    "# prediction_client = automl.PredictionServiceClient()\n",
    "\n",
    "# A resource that represents Google Cloud Platform location.\n",
    "#project_location = automl_client.location_path(project_id, compute_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create, Append and Export csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_img_folders(label):\n",
    "    \"\"\"Organize img in their corresponding label folder.\n",
    "    The folder needs to be classed whale_data and contain all images\"\"\"\n",
    "    os.mkdir('./whale_data/{}'.format(label))\n",
    "    lst_img_label = list(df[df['Id']=='{}'.format(label)].Image.values)\n",
    "    for img in lst_img_label:\n",
    "        shutil.move('./whale_data/{}'.format(img),\n",
    "                    './whale_data/{}/{}'.format(label,img))\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./WhaleTail.csv')\n",
    "labels_list = list(df.Id.value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = list(df.Id.value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize folder per label\n",
    "for label in labels_list:\n",
    "    org_img_folders(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby('Id').agg({'Image':'count'}).reset_index()\\\n",
    "                                        .sort_values(by='Image',\n",
    "                                                 ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25361 images of whale tails\n"
     ]
    }
   ],
   "source": [
    "print ('There are {} images of whale tails'.format(df_agg.Image.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbr_class_wt_n_images(n):\n",
    "    return df_agg[df_agg['Image']==n].Image.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize your model datasets\n",
    "* Hypothesis:\n",
    "\n",
    "new_whale images are wrongly unclassified.\n",
    "\n",
    "* Verify hypothesis:\n",
    "\n",
    "predict new_whale images on models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nbr_labels(label):\n",
    "        nbr_files = []\n",
    "        for fileList in os.listdir('./whale_data/{}'.format(label)):\n",
    "            nbr_files.append(fileList)\n",
    "        return nbr_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset_1m(label):\n",
    "\n",
    "    nbr_files = compute_nbr_labels(label)\n",
    "\n",
    "    for i in range(0,len(nbr_files)):\n",
    "        # Setting minimum 100 images per class\n",
    "        if (100-len(nbr_files)) > 0:\n",
    "            # Augmenting by the factor that is dependent on nbr images\n",
    "            # already present\n",
    "            for augment_idx in range(0,int(ceil((100-len(nbr_files))/len(nbr_files)))):\n",
    "                try:\n",
    "                    image = np.array(Image.open('./whale_data/{}/{}'.format(label,nbr_files[i])))\n",
    "                    # If image is grayscale, resize to 3 channel np array\n",
    "                    if len(image.shape) ==2:\n",
    "                        image = np.resize(image, (image.shape[0], image.shape[1], 3))\n",
    "                    \n",
    "                    # data aug methods requires 3D arrays\n",
    "                    result = seq.augment_image(image)\n",
    "                    scipy.misc.imsave(\"./whale_data/{}/aug{}{}\".format(label,augment_idx,nbr_files[i]),result)\n",
    "                except Exception:\n",
    "                    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate these classes and build a model just for these\n",
    "model_1_dataset_labels = list(df_agg[1:6].Id.values)\n",
    "model_2_dataset_labels = list(df_agg[6:].Id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: create CSV\n",
    "def export_automl_csv(curated_label_list, dataset_name):\n",
    "    csv_VM_path= './automl_WhaleTail_{}.csv'.format(dataset_name)\n",
    "    with open(csv_VM_path,'w') as newFile:\n",
    "        newFileWriter = csv.writer(newFile)\n",
    "        for label in curated_label_list:\n",
    "            lst_files = compute_nbr_labels(label)\n",
    "            for i in range(len(lst_files)):\n",
    "                img_gcs_path = 'gs://{}/WhaleTail/{}'\\\n",
    "                                .format(bucket_name,lst_files[i])\n",
    "                newFileWriter.writerow([img_gcs_path,label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_automl_csv(model_2_dataset,'hypothese1Dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "# e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "# Define our sequence of augmentation steps that will be applied to every image\n",
    "# All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "# in 50% of all cases. In all other cases they will sample new values\n",
    "# _per channel_.\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        # apply the following augmenters to most images\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "        iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "        # crop images by -5% to 10% of their height/width\n",
    "        sometimes(iaa.CropAndPad(\n",
    "            percent=(-0.05, 0.1),\n",
    "            pad_mode=ia.ALL,\n",
    "            pad_cval=(0, 255)\n",
    "        )),\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "            rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "            shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "            order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "        )),\n",
    "        # execute 0 to 5 of the following (less important) augmenters per image\n",
    "        # don't execute all of them, as that would often be way too strong\n",
    "        iaa.SomeOf((0, 5),\n",
    "            [\n",
    "                sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                    iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                    iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                ]),\n",
    "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                # search either for all edges or for directed edges,\n",
    "                # blend the result with the original image using a blobby mask\n",
    "                iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                    iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                    iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                ])),\n",
    "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                iaa.OneOf([\n",
    "                    iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "                ]),\n",
    "                iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "                iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\n",
    "                # either change the brightness of the whole image (sometimes\n",
    "                # per channel) or change the brightness of subareas\n",
    "                iaa.OneOf([\n",
    "                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                    iaa.FrequencyNoiseAlpha(\n",
    "                        exponent=(-4, 0),\n",
    "                        first=iaa.Multiply((0.5, 1.5), per_channel=True),\n",
    "                        second=iaa.ContrastNormalization((0.5, 2.0))\n",
    "                    )\n",
    "                ]),\n",
    "                iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "                iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "                sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "            ],\n",
    "            random_order=True\n",
    "        )\n",
    "    ],\n",
    "    random_order=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for VM_path, subdirList, fileList in os.walk('./whale_data'):\n",
    "#     print len(subdirList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend running this cell on the VM directly\n",
    "# augmented_labels = 0\n",
    "# for label in labels_list:\n",
    "#     augment_dataset_1m(label)\n",
    "#     augmented_labels +=1\n",
    "#     print (augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(local_path, bucket_name,dataset_name):\n",
    "    \"\"\"Upload CSV file.\"\"\"\n",
    "\n",
    "    csv_VM_path = './data/{}.csv'.format(dataset_name)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    output_gcs_path = 'csv/{}.csv'.format(dataset_name)\n",
    "    blob = bucket.blob(output_gcs_path)\n",
    "    blob.upload_from_filename(csv_VM_path)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_blob(csv_VM_path,bucket_name,dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Statistic on the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) separation of models in a logical manner (1,000,000 images per dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Take the 5000 classes with the least amount of images\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create automl dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_automl_dataset(project_id,compute_region,dataset_name):\n",
    "    \"\"\"Create a placeholder dataset.\"\"\"\n",
    "#     project_id = args['project_id']\n",
    "#     compute_region = args['compute_region']\n",
    "#     dataset_name = args['dataset_name']\n",
    "\n",
    "    # Classification type is assigned based on multilabel value.\n",
    "    classification_type = \"MULTICLASS\"\n",
    "\n",
    "    # Specify the image classification type for the dataset.\n",
    "    dataset_metadata = {\"classification_type\": classification_type}\n",
    "    # Set dataset name and metadata of the dataset.\n",
    "    my_dataset = {\n",
    "        \"display_name\": dataset_name,\n",
    "        \"image_classification_dataset_metadata\": dataset_metadata,\n",
    "    }\n",
    "    \n",
    "    # Create dataset\n",
    "    # First verify that the name doesnt already exists\n",
    "    list_dataset = automl_client.list_datasets(project_location)\n",
    "    for dataset in list_dataset:\n",
    "        if dataset.display_name == dataset_name:\n",
    "            dataset_id = dataset.name.split(\"/\")[-1]\n",
    "            print (\"dataset name already used by dataset id: {}\".format(dataset_id))\n",
    "            \n",
    "            dataset_full_id = automl_client.dataset_path(project_id, \n",
    "                                                  compute_region, \n",
    "                                                  dataset_id)\n",
    "\n",
    "            # Get complete detail of the dataset.\n",
    "            dataset_info = automl_client.get_dataset(dataset_full_id)\n",
    "            return dataset_info\n",
    "               \n",
    "    # Create new one\n",
    "    dataset_info = automl_client.create_dataset(project_location, my_dataset)\n",
    "    return dataset_info\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset name already used by dataset id: ICN6639741849712435570\n"
     ]
    }
   ],
   "source": [
    "dataset_info = create_automl_dataset(project_id,\n",
    "                                     compute_region,\n",
    "                                     dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(project_id,compute_region, \n",
    "                   dataset_info, dataset_name):\n",
    "    \"\"\"Fill in the dataset placeholder.\"\"\"\n",
    "    dataset_id = dataset_info.name.split(\"/\")[-1]\n",
    "#     project_id = args['project_id']\n",
    "#     compute_region = args['compute_region']\n",
    "\n",
    "    gcs_csv_path = 'gs://aketari-sandbox-vision-vcm/csv/{}.csv'.format(dataset_name)\n",
    "    # Get the full path of the dataset.\n",
    "    dataset_full_id = automl_client.dataset_path(\n",
    "        project_id, compute_region, dataset_id\n",
    "    )\n",
    "\n",
    "    # Get the multiple Google Cloud Storage URIs.\n",
    "    input_uris = gcs_csv_path.split(\",\")\n",
    "    input_config = {\"gcs_source\": {\"input_uris\": input_uris}}\n",
    "\n",
    "    # Import data from the input URI.\n",
    "    response = automl_client.import_data(dataset_full_id, input_config)\n",
    "\n",
    "    print(\"Processing import...\")\n",
    "    # synchronous check of operation status.\n",
    "    print(\"Data imported. {}\".format(response.result())) \n",
    "    print(\"Well, not exactly. You still have to wait about 15 min, \\\n",
    "        before training any model on this data\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing import...\n",
      "Data imported. \n"
     ]
    }
   ],
   "source": [
    "import_dataset(project_id, compute_region, \n",
    "               dataset_info,dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train Automl model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset_info, version, train_budget=1):\n",
    "    \"\"\"Train model\"\"\"\n",
    "    \n",
    "    dataset_id = dataset_info.name.split(\"/\")[-1]\n",
    "    model_name = model_name_prefix + str(version)\n",
    "    \n",
    "    models_list = automl_client.list_models(project_location)\n",
    "    for model in models_list:\n",
    "        if model.display_name == model_name:\n",
    "            version += 1\n",
    "            model_name = model_name_prefix + str(version)\n",
    "    \n",
    "    # Set model name and model metadata for the image dataset.\n",
    "    my_model = {\n",
    "        \"display_name\": model_name,\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"image_classification_model_metadata\": \\\n",
    "                                        {\"train_budget\": train_budget}\n",
    "        if train_budget\n",
    "        else {},\n",
    "    }\n",
    "\n",
    "    # Create a model with the model metadata in the region.\n",
    "    model = automl_client.create_model(project_location, my_model)\n",
    "    print (\"Training operation name: {}\".format(model.operation.name))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Execute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(dataset_info,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model called: Mars_model_1\n",
      "Model id: ICN4656393435248390578\n",
      "==================\n",
      "Model called: WaterOnMars_v20181209024327\n",
      "Model id: ICN1070916309218507773\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "# Choose a deployed model:\n",
    "models_list = automl_client.list_models(project_location)\n",
    "for model in models_list:\n",
    "    print ('Model called: {}'.format(model.display_name))\n",
    "    print ('Model id: {}'.format(model.name.split('/')[-1]))\n",
    "    print ('==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'ICN4656393435248390578'\n",
    "model_full_id = automl_client.model_path(project_id, \n",
    "                                         compute_region, \n",
    "                                         model_id)\n",
    "\n",
    "# Get complete detail of the model.\n",
    "model = automl_client.get_model(model_full_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, bucket_name, gcs_path,\n",
    "             local_path=None, score_threshold='0.5'):\n",
    "    \"\"\"\n",
    "    gcs_path = folder_1/folder_n/image_title\n",
    "    \"\"\"\n",
    "    model_id = model.name.split(\"/\")[-1]\n",
    "    # Get the full path of the model.\n",
    "    model_full_id = automl_client.model_path(\n",
    "        project_id, compute_region, model_id)\n",
    "\n",
    "    # Read the image and assign to payload.\n",
    "    if local_path == None:\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(gcs_path)\n",
    "        content = blob.download_as_string()\n",
    "    \n",
    "    else:\n",
    "        with open(local_path, \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "            \n",
    "    payload = {\"image\": {\"image_bytes\": content}}\n",
    "\n",
    "    # params is additional domain-specific parameters.\n",
    "    # score_threshold is used to filter the result\n",
    "    # Initialize params\n",
    "    params = {}\n",
    "    if score_threshold:\n",
    "        params = {\"score_threshold\": score_threshold}\n",
    "\n",
    "    pred_response = prediction_client.predict(model_full_id, payload, params)\n",
    "    print(\"Prediction results:\")\n",
    "    for result in pred_response.payload:\n",
    "        print(\"Predicted class name: {}\".format(result.display_name))\n",
    "        print(\"Predicted class score: {}\".format(result.classification.score))\n",
    "    return pred_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_pred_csv(img_title,pred):\n",
    "    \n",
    "    predicted_class = pred.display_name\n",
    "    pred_path = './data/preds.csv'\n",
    "    \n",
    "    if os.path.isdir('./data/preds.csv') == True:\n",
    "        with open(pred_path,'a') as newFile:\n",
    "            newFile.writerow([img_title,predicted_class])\n",
    "    else:\n",
    "        os.mkdir('./data/preds.csv')\n",
    "        with open(pred_path,'w') as newFile:\n",
    "            newFileWriter = csv.writer(newFile)\n",
    "            newFileWriter.writerow([img_title,predicted_class])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results:\n",
      "Predicted class name: NoWater\n",
      "Predicted class score: 0.999988555908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "payload {\n",
       "  classification {\n",
       "    score: 0.999988555908\n",
       "  }\n",
       "  display_name: \"NoWater\"\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model,bucket_name,\n",
    "              gcs_path='WaterOnMars/images/aILz6npGtaM.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'ICN3937997390383836716'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
